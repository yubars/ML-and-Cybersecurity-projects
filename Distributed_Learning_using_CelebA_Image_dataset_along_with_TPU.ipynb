{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Distributed Learning using CelebA Image dataset along with TPU",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yubars/ML-and-Cybersecurity-projects/blob/main/Distributed_Learning_using_CelebA_Image_dataset_along_with_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7dabOS3yNR4"
      },
      "source": [
        "# Distributed Learning using CelebA Image dataset along with TPU\n",
        "### Making use of TPU Strategy to implement clusters for distributed learning using TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_zpHZRWyNIy"
      },
      "source": [
        "### Learning Objectives\n",
        "* Understand how Distributed learning works (using CNN)\n",
        "* Learn the difference- between Distributed Learning and Federated Learning.\n",
        "* Learn to use TPUStrategy for distributed learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oSPPVfMMBDq"
      },
      "source": [
        "### Imports\n",
        "Import all the necessary libraries for the lab such as tensorflow, numpy, pandas, and keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkDtRy4H1Bks"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "import cv2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS8ZJwkXPLZ3"
      },
      "source": [
        "### Mount Google Drive\n",
        "\n",
        "In the code cell below, we mount the google drive to the colab environment so that we have access to the local version of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyIF3OVJ1bqc",
        "outputId": "993339b4-e7a1-487c-f300-3e4716dfd2fa"
      },
      "source": [
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zgQ0NPYPRvw"
      },
      "source": [
        "### Read CSV\n",
        "Use Pandas to load CelebA Image dataset from the CSV file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saIAoAqE4Qsd"
      },
      "source": [
        "#read the csv file to access the feature \"Smiling\"\n",
        "mydata = pd.read_csv('/content/drive/My Drive/Intro2MLDatasets/Lab9/list_attr_celeba.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTrLOmiLPY04"
      },
      "source": [
        "### Drop features\n",
        "Drop the features from the dataset which are not needed. Smiling is the label to be predicted and the Image ID  is used as an identifier. All the other features are excluded from the dataset because in this lab we are reading each pixel of an image to be used as a feature and the Smiling attribute as a label. The prediction depends on the model which learns from the pixels of an image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0fBoAw44UNK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "aa62e86c-d3dd-44ee-fcf3-1d05f82895e3"
      },
      "source": [
        "#drop all the other features from the csv except for the image_id and smiling\n",
        "mydata.drop(mydata.columns.difference(['image_id','Smiling']), 1, inplace=True)\n",
        "mydata.head(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>Smiling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004.jpg</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005.jpg</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>000096.jpg</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>000097.jpg</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>000098.jpg</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>000099.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>000100.jpg</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      image_id  Smiling\n",
              "0   000001.jpg        1\n",
              "1   000002.jpg        1\n",
              "2   000003.jpg       -1\n",
              "3   000004.jpg       -1\n",
              "4   000005.jpg       -1\n",
              "..         ...      ...\n",
              "95  000096.jpg       -1\n",
              "96  000097.jpg       -1\n",
              "97  000098.jpg       -1\n",
              "98  000099.jpg        1\n",
              "99  000100.jpg       -1\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4R1EP9-PtHc"
      },
      "source": [
        "### Labels List\n",
        "Create a list named Label which corresponds to the feature Smiling. This list will be used later to create training and testing data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7AIjjep2_hl"
      },
      "source": [
        "labels = list()\n",
        "\n",
        "# Iterate over dataframe to store target labels for attribute \"Smiling\"\n",
        "# Store all the attribute values for Smiling in labels \n",
        "for (columnName, columnData) in mydata.iteritems():\n",
        "  if columnName == 'Smiling':\n",
        "    for i in range(0, 2988):\n",
        "      labels.append(columnData.values[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90frmiXFPz5H"
      },
      "source": [
        "### Read image to convert into an array\n",
        "Load function reads the images from the path provided as a list to the function. It reads the image, flattens the pixel value, and scales it to value [0,1] and returns the list of lists where each list is the scaled pixel value of one image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU_1j0Z30obt"
      },
      "source": [
        "#Given a path, iterate over and read each image and convert to an array \n",
        "def load(path):\n",
        "  data = list()\n",
        "\n",
        "  for imgpath in path:\n",
        "    im_grayscale= cv2.imread(imgpath, 0)\n",
        "    image = np.array(im_grayscale)\n",
        "    # .flatten()\n",
        "    # image = image.reshape((218, 178, 1))\n",
        "    #scales the image to [0,1] and adds to the list\n",
        "    data.append(image/255)\n",
        "\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae7oMj64QGoG"
      },
      "source": [
        "### Image path\n",
        "Create path for each image from the folder and call the load function. The length of image_list and labels are equal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLTRfSaoeWlF"
      },
      "source": [
        "image_path = '/content/drive/My Drive/Intro2MLDatasets/images_celeba'\n",
        "img_paths = list(paths.list_images(image_path)) \n",
        "\n",
        "image_list = load(img_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbE3tN-dQLre"
      },
      "source": [
        "### Convert labels into binary and split data\n",
        "Convert the label into binary format and split the data into train and test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R4rTN2znTgK"
      },
      "source": [
        "#convert the label into binary data 0 or 1\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "\n",
        "#Split feature and label into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(image_list, labels, test_size=0.1, shuffle=True)\n",
        "\n",
        "#convert all the variables to numpy array, and float32 type \n",
        "x_train = np.asarray(x_train).astype(np.float32)\n",
        "x_test = np.asarray(x_test).astype(np.float32)\n",
        "y_train = np.asarray(y_train).astype(np.float32)\n",
        "y_test = np.asarray(y_test).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og3zLsR4t6g4"
      },
      "source": [
        "### Create Model\n",
        "Create Neural network model with multiple layers. The functionality for each layers are defined below in the code cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yK2FyvqMoqB"
      },
      "source": [
        "https://www.kaggle.com/pavansanagapati/a-simple-cnn-model-beginner-guide"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5RP0VL0poaS"
      },
      "source": [
        "def create_model(shape, classes):\n",
        "  model = Sequential()\n",
        "  \"\"\"\n",
        "  (218, 178, 3) is the shape of celebA image datasets.\n",
        "  # Batch Normalization is used to make neural networks faster and more stable through normalization of layers inputs by recentering and rescaling. It maintains mean output close to 0 and the standard deviation close to 1.\n",
        "  Conv2D is basically a 2D convolutional layer used for image processing kernel which helps produce a tensor of outputs.\n",
        "  Maxpooling2D downsamples the input along its spatial dimension(height and width). The window is shifted by strides along each dimension.\n",
        "  Dropout prevents overfitting. Fraction of input units to drop.\n",
        "  Dense layer is the network layer in the model which feeds all outputs from the previous layer to all its neurons. Each neuron provides one output to the next layer.\n",
        "  \"\"\"\n",
        "\n",
        "  model.add(Conv2D(64, input_shape=shape, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(200, activation=\"relu\"))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(200, activation=\"relu\"))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(classes, activation=\"sigmoid\"))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8nWcLS8zwQ1"
      },
      "source": [
        "### TPU \n",
        "Using TPU strategy for synchronous training on TPUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdRu6zDrI_vo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "7a1dbec9-f4df-40fd-cbc9-4f0a8bf1da8d"
      },
      "source": [
        "\"\"\"\n",
        "tf.distribute.TPUStrategy lets you run your tf training on Tensor Processing Units (TPU). TPUs dramatically accelerates machine learning workloads.  \n",
        "TPUStrategy implements synchronous distributed training. TPUs provide their own implementation of efficient all-reduce and other collective operations across multiple TPU cores.\n",
        "\"\"\"\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "\n",
        "with strategy.scope():\n",
        "  model = create_model((218, 178, 1), 1)\n",
        "  model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-6207745d3a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTPUStrategy\u001b[0m \u001b[0mimplements\u001b[0m \u001b[0msynchronous\u001b[0m \u001b[0mdistributed\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mTPUs\u001b[0m \u001b[0mprovide\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mown\u001b[0m \u001b[0mimplementation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mefficient\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreduce\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m \u001b[0mcollective\u001b[0m \u001b[0moperations\u001b[0m \u001b[0macross\u001b[0m \u001b[0mmultiple\u001b[0m \u001b[0mTPU\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_connect_to_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_tpu_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tpu, zone, project, job_name, coordinator_name, coordinator_address, credentials, service, discovery_url)\u001b[0m\n\u001b[1;32m    205\u001b[0m           \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0mservice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m           discovery_url=discovery_url)\n\u001b[0m\u001b[1;32m    208\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cloud_tpu_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/tpu/client/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tpu, zone, project, credentials, service, discovery_url)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtpu\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please provide a TPU Name to connect to.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Please provide a TPU Name to connect to."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uDO42YAJNak"
      },
      "source": [
        "tf.get_logger().setLevel('ERROR')\n",
        "validation_frequency = 5\n",
        "history = model.fit(x_train, \n",
        "                    y_train, \n",
        "                    epochs=15,\n",
        "                    steps_per_epoch=30,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    validation_freq=validation_frequency)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWLP-bVcgDcu"
      },
      "source": [
        "def plot_training_history(history, title=None):\n",
        "    fig = plt.figure(figsize=(9,9))\n",
        "    plt.plot(history['accuracy'], label='acc')\n",
        "    plt.plot(history['loss'], label='loss')\n",
        "    plt.plot(history['val_accuracy'], label='val_acc')\n",
        "    plt.plot(history['val_loss'], label='val_loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy and loss plot')\n",
        "    plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KBs-BnWgH0T"
      },
      "source": [
        "for metric in [\"loss\", \"accuracy\"]:\n",
        "    metric_series = history.history[metric]\n",
        "    print('break', history.history[metric])\n",
        "    print(metric_series)\n",
        "\n",
        "    temp = []\n",
        "    for i in range(0, len(metric_series), validation_frequency):\n",
        "      temp.append(metric_series[i])\n",
        "    history.history[metric] = temp\n",
        "    \n",
        "    print('break2', history.history[metric])\n",
        "\n",
        "plot_training_history(history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckqKxZ2YjZU9"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN0embIbnFkr"
      },
      "source": [
        " **Assignment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BcTDWwoO5Im"
      },
      "source": [
        "**We have ML scenario with 100 devices which could use Federated Learning (FL) or Distributed Learning (DL). Let's assume that each device generates 25GB of data every hour. Let's consider that the DL and FL training process takes more or less same time (say approx. 20 minutes). For this scenario, answer the following questions:**\n",
        "  \n",
        "1. **In Distributed Learning, how long would it take to exchange this data using 100 Mbps communication link if we are updating the learning model every hour? Approximately how long would it take to get the learning model ready for inferencing or prediction for each device?**\n",
        "\n",
        "Assuming parallel exhanges between all nodes, \n",
        "\n",
        "Time taken to exchange 25GB hourly data in 100 Mbps link = (25GB /100 Mbps)/60 min\n",
        "=(25 x 1024 x 8 )/(100 x 60) Mins\n",
        "=34.13 mins\n",
        "\n",
        "Time taken to get learning model ready for infeencing  = 34.13 min + 20 min training time\n",
        "                      = 54.13 mins\n",
        "2. **In Federated Learning, how long would it take to exchange 100 parameters(each parameter is 1KBytes) from each client to FL server using 100 Mbps communication link if we are updating the learning model every hour and sending the global model back to the client? Let's assume that FL server takes about 2 mins for generating global model. Approximately how long would it take to get the learning model ready for inferencing or prediction for each device?**\n",
        "\n",
        "Time taken to get learning model ready for prediction \n",
        "= 20 min (device training time) + 2 min (global  model generation time) + 2 x (100 x 1 x 8)/(100 x 1024 x 60) = 22.00026 Min\n",
        "\n",
        "\n",
        "3. **Based on 1 and 2, provide your observations on DL and FL.**\n",
        "\n",
        "Based of 1 and 2, I observed that Federated learnig is far better than distributed learning in terms of time performance. Additionally, Federated learning perserves user privacy and enhances security by not sharing data to others as it only sends parameters to global server only. However, if we consider accuracy, DL might perform better than FL."
      ]
    }
  ]
}
